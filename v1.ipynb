{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu121 running on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"{torch.__version__} running on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP Run for Image Classification\n",
    "Your problem needs to fulfill the following criteria.\n",
    "1. It is an image classification problem.\n",
    "2. You supply marked training images and marked validation images.\n",
    "\n",
    "Within those, the run is flexible and adapts itself to your problem.\n",
    "Now, please describe your images and problem by setting those global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 28 # <-- number of width-pixels\n",
    "IMAGE_HEIGHT = 28 # <-- number of height-pixels\n",
    "COLOUR_CHANNEL_COUNT = 1 # <-- RGB images would have 3\n",
    "CLASSIFICATION_CATEGORIES_COUNT = 10 # <-- the amount of possible categories of which each image shall be marked with one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Individuals' Class\n",
    "- The Hyperparamters should be passed to the constructor in a way that is both convenient for GP and for PyTorch.\n",
    "- I think I want to define a class for one `nn.Sequential` 2d-block\n",
    "    - All possible instances should be concatenable with all possible instances\n",
    "- Then, an individual is built from the concatenation of many such blocks, plus data preparation and final f.c. layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "define a Î» nn.Module that creates an nn layer from a given function\n",
    "this is handy for nn.Sequential usage '''\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "    \n",
    "'''\n",
    "create a function to reshape the (28x28) image input data '''\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testX.shape = torch.Size([1, 28, 28])\n",
      "testX[:,:3]: tensor([[[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431,\n",
      "          -1.6047, -0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594,\n",
      "          -0.7688,  0.7624,  1.6423, -0.1596, -0.4974,  0.4396, -0.7581,\n",
      "           1.0783,  0.8008,  1.6806,  1.2791,  1.2964,  0.6105,  1.3347],\n",
      "         [-0.2316,  0.0418, -0.2516,  0.8599, -1.3847, -0.8712, -0.2234,\n",
      "           1.7174,  0.3189, -0.4245,  0.3057, -0.7746, -1.5576,  0.9956,\n",
      "          -0.8798, -0.6011, -1.2742,  2.1228, -1.2347, -0.4879, -0.9138,\n",
      "          -0.6581,  0.0780,  0.5258, -0.4880,  1.1914, -0.8140, -0.7360],\n",
      "         [-1.4032,  0.0360, -0.0635,  0.6756, -0.0978,  1.8446, -1.1845,\n",
      "           1.3835,  1.4451,  0.8564,  2.2181,  0.5232,  0.3466, -0.1973,\n",
      "          -1.0546,  1.2780, -0.1722,  0.5238,  0.0566,  0.4263,  0.5750,\n",
      "          -0.6417, -2.2064, -0.7508,  0.0109, -0.3387, -1.3407, -0.5854]]])\n",
      "testBlock1(testX).shape = torch.Size([5, 14, 14])\n",
      "testBlock1(testX)[:1,:3]: tensor([[[0.1440, 0.8781, 0.9674, 0.6525, 0.7593, 1.0841, 0.7989, 0.3180,\n",
      "          0.3287, 0.6869, 0.4369, 0.0000, 0.0106, 0.1710],\n",
      "         [0.6367, 0.2177, 1.0848, 0.2897, 0.0000, 0.0282, 1.1142, 0.7964,\n",
      "          0.4307, 0.5883, 0.3206, 1.0784, 0.4747, 0.5563],\n",
      "         [0.5163, 0.6823, 0.0457, 0.5422, 0.7757, 0.0914, 0.8209, 0.2757,\n",
      "          0.6587, 0.5162, 0.6592, 0.0000, 0.1581, 0.7042]]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Sequential_block_2d(nn.Module):\n",
    "    def __init__(self, \n",
    "                 out_channels: int, # the number of output neurons after the full block\n",
    "                 in_channels: int = 1, # should not be set here, but is set in Individual's __init__()\n",
    "                 conv_kernel_size: int = 3,\n",
    "                 conv_stride: int = 1,\n",
    "                 conv_padding: int = 1,\n",
    "                 pool_kernel_size: int = 2,\n",
    "                 pool_stride: int = 2,\n",
    "                 pool_padding: int = 0):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels,\n",
    "                      out_channels=out_channels,\n",
    "                      kernel_size=conv_kernel_size,\n",
    "                      stride=conv_stride,\n",
    "                      padding=conv_padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_kernel_size,\n",
    "                         stride=pool_stride,\n",
    "                         padding=pool_padding)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "# generate some testing blocks (TODO: write actual unit tests)\n",
    "testBlock1 = Sequential_block_2d(in_channels=1,out_channels=5)\n",
    "testBlock2 = Sequential_block_2d(in_channels=5,out_channels=3)\n",
    "torch.manual_seed(42)\n",
    "testX = torch.randn(COLOUR_CHANNEL_COUNT,IMAGE_WIDTH,IMAGE_HEIGHT)\n",
    "testBlock1, testBlock2, testX, testBlock1(testX)\n",
    "print(f\"testX.shape = {testX.shape}\\ntestX[:,:3]: {testX[:,:3]}\")\n",
    "print(f\"testBlock1(testX).shape = {testBlock1(testX).shape}\\ntestBlock1(testX)[:1,:3]: {testBlock1(testX)[:1,:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0964, -0.0073, -0.2285, -0.0881, -0.0110,  0.2158,  0.0744,  0.2094,\n",
       "        -0.1230,  0.4733], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class for image classification individuals\n",
    "class NN_individual(nn.Module):\n",
    "    def __init__(self, blocks_2d: list[Sequential_block_2d],\n",
    "                 in_dimensions: int = COLOUR_CHANNEL_COUNT,\n",
    "                 out_dimensions: int = CLASSIFICATION_CATEGORIES_COUNT,\n",
    "                 fin_res: int = 5): # output dimension of the final max pooling \n",
    "                                    # producing size (fin_res * fin_res)\n",
    "        super().__init__()\n",
    "        self.blocks_2d = blocks_2d\n",
    "        # add a final max pool\n",
    "        # Why? Because then torch handles the dimensions through the \"adaptive\"ness\n",
    "        self.last_max_pool_adaptive = nn.AdaptiveAvgPool2d((fin_res, fin_res))\n",
    "        self.flatten = nn.Flatten(start_dim=0, end_dim=-1) # default start_dim = 1\n",
    "        self.lin = nn.Linear(in_features = fin_res * fin_res * blocks_2d[-1].out_channels,\n",
    "                      out_features = out_dimensions)\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.blocks_2d)):\n",
    "            x = self.blocks_2d[i](x)\n",
    "        x = self.last_max_pool_adaptive(x)\n",
    "        #print(f\"last_max_pool_adaptive output shape is {x.shape}\")\n",
    "        x = self.flatten(x)\n",
    "        #print(f\"flatten output shape is {x.shape}\")\n",
    "        x = self.lin(x)\n",
    "        #print(f\"lin output shape is {x.shape}\")\n",
    "        return x\n",
    "    \n",
    "testIndividual = NN_individual(blocks_2d=[testBlock1, testBlock2])\n",
    "testIndividual(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_channels of the first needs to match in_channels of the second!\n",
      "in_channels of the first gene needs to match the COLOUR_CHANNEL_COUNT of the problem!\n"
     ]
    }
   ],
   "source": [
    "# this way, adjacent genes (= 2d_blocks) need to have the correct dimensions\n",
    "# e.g. the following will error:\n",
    "badIndividual = NN_individual([Sequential_block_2d(in_channels=1,out_channels=2), Sequential_block_2d(in_channels=3, out_channels=5)])\n",
    "try:\n",
    "    print(badIndividual(testX))\n",
    "except:\n",
    "    print(\"out_channels of the first needs to match in_channels of the second!\")\n",
    "\n",
    "# but there's more redundancy:\\the first gene needs to have the same number of in_channels as there are colour channels\n",
    "# e.g. the following will error:\n",
    "badIndividual = NN_individual([Sequential_block_2d(in_channels=COLOUR_CHANNEL_COUNT + 1,out_channels=5)])\n",
    "try:\n",
    "    print(badIndividual(testX))\n",
    "except:\n",
    "    print(\"in_channels of the first gene needs to match the COLOUR_CHANNEL_COUNT of the problem!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brainstorm on How to Encode Individuals\n",
    "We need to talk about this right now because we want to adapt our `NN_individual.blocks_2d` definition according to it.\n",
    "The options are:\n",
    "1. We specify `Sequential_block_2d.in_channels` and `~.out_channels` separately for each individual and only allow concatenation if the criteria are met. This is probably not super clever...\n",
    "2. Genotype-closure: The parameters that are adapted through GP will never leave the space of syntacticly correct indivuals\n",
    "    - The first gene is not allowed to choose `~.in_channels`, it must match `COLOUR_CHANNEL_COUNT`\n",
    "    - Every gene but the first is not allowed to choose `~.in_channels`, it must match `~.out_channels` of the prior gene\n",
    "    - How will this change the gene class `Sequential_block_2d`?\n",
    "        - Set `Sequential_block_2d.in_channels` only programatically, in `NN_individual.__init__()`\n",
    "        - Don't even let the genes inherit from `nn.Module`, only the individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for the genetic information of one 2d block\n",
    "class Gene_2d_block:\n",
    "    def __init__(self,\n",
    "                 out_channels: int,\n",
    "                 in_channels: int = None, # set in the individual's constructor\n",
    "                 conv_kernel_size: int = 3,\n",
    "                 conv_stride: int = 1,\n",
    "                 conv_padding: int = 1,\n",
    "                 pool_kernel_size: int = 2,\n",
    "                 pool_stride: int = 2,\n",
    "                 pool_padding: int = 0):\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_kernel_size = conv_kernel_size\n",
    "        self.conv_stride = conv_stride\n",
    "        self.conv_padding = conv_padding\n",
    "        self.pool_kernel_size = pool_kernel_size\n",
    "        self.pool_stride = pool_stride\n",
    "        self.pool_padding = pool_padding\n",
    "\n",
    "    def toString(self, tab_count: int = 0):\n",
    "        indentation = \"\"\n",
    "        for tab in range(tab_count): indentation += f\"\\t\"\n",
    "        return f\"{indentation}out_channels = {self.out_channels}\\n\"+\\\n",
    "        f\"{indentation}conv_2d (kernel, stride, padding) =\\t({self.conv_kernel_size}, {self.conv_stride}, {self.conv_padding})\\n\"+\\\n",
    "        f\"{indentation}max_pool_2d (kernel, stride, padding) =\\t({self.pool_kernel_size}, {self.pool_stride}, {self.pool_padding})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(NN_individual(\n",
       "   (blocks_2d): Sequential(\n",
       "     (0): Sequential(\n",
       "       (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): ReLU()\n",
       "       (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Conv2d(4, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): ReLU()\n",
       "       (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "   )\n",
       "   (flatten): Flatten(start_dim=0, end_dim=-1)\n",
       "   (lazyLin): Linear(in_features=343, out_features=10, bias=True)\n",
       " ),\n",
       " tensor([-0.0134, -0.0387, -0.0594,  0.0336,  0.0421,  0.0608, -0.1380, -0.0417,\n",
       "          0.1144,  0.0008], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class for image classification individuals\n",
    "class NN_individual(nn.Module):\n",
    "    def __init__(self, genes_2d_block: list[Gene_2d_block], name=\"nn0\"): \n",
    "        super().__init__()\n",
    "        self.name=name # a name for easier tracking inside a GP run\n",
    "        ''' build the full sequential from the gene information (genes_2d_block) '''\n",
    "        self.blocks_2d = nn.Sequential()\n",
    "        # the first 2d_block needs to have as many in_channels as there are colour channels\n",
    "        # the others need to have as in_channels the number of out_channels from the previous block\n",
    "        for i in range(len(genes_2d_block)):\n",
    "            if i == 0:\n",
    "                in_channels = COLOUR_CHANNEL_COUNT\n",
    "            else:\n",
    "                in_channels = genes_2d_block[i-1].out_channels\n",
    "            self.blocks_2d.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels,\n",
    "                    out_channels=genes_2d_block[i].out_channels,\n",
    "                    kernel_size=genes_2d_block[i].conv_kernel_size,\n",
    "                    stride=genes_2d_block[i].conv_stride,\n",
    "                    padding=genes_2d_block[i].conv_padding),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=genes_2d_block[i].pool_kernel_size,\n",
    "                    stride=genes_2d_block[i].pool_stride,\n",
    "                    padding=genes_2d_block[i].pool_padding)))\n",
    "        self.flatten = nn.Flatten(start_dim=0, end_dim=-1) # default start_dim = 1\n",
    "        self.lazyLin = nn.LazyLinear(out_features = CLASSIFICATION_CATEGORIES_COUNT) # automatically infers the number of channels\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.blocks_2d)):\n",
    "            x = self.blocks_2d[i](x)\n",
    "        x = self.flatten(x)\n",
    "        #print(f\"flatten output shape is {x.shape}\")\n",
    "        x = self.lazyLin(x)\n",
    "        #print(f\"lin output shape is {x.shape}\")\n",
    "        return x\n",
    "    \n",
    "testIndividual = NN_individual(genes_2d_block=[Gene_2d_block(out_channels=4), Gene_2d_block(out_channels=7)])\n",
    "testIndividual, testIndividual(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Code\n",
    "Now we need to decide the genetic stuff.\n",
    "1. Initial Population\n",
    "2. Fitness Measure\n",
    "3. Selection\n",
    "4. Genetic Operators\n",
    "    - Cloning or Crossover\n",
    "    - Mutation\n",
    "    \n",
    "### Hyperparameter-landscape is vast. Here's a list:\n",
    "- Net architecture\n",
    "    - kind of layers, number of layers\n",
    "        - for convolution/pooling: kernel size, stride, padding, (dilation) **[implemented]**\n",
    "    - number of neurons per layer\n",
    "    - activation function for each layer\n",
    "- cost function\n",
    "    - base term (e.g. square cost, log-likelihood, cross-entropy, ect.)\n",
    "    - toppings \n",
    "        - regularization of weights (L2, L1, dropout, etc.)\n",
    "- weights and biases optimization technique (= optimizer)\n",
    "    - SGD (= stochastic gradient descent)\n",
    "    - Hessian technique, i.e. momentum-based descent\n",
    "    - PyTorch's various other (e.g. *Adam* optimizer)\n",
    "- learning parameters\n",
    "    - Î· ... learning rate\n",
    "        - constant, or epoch-dependent, or accuracy-dependent, or a mix\n",
    "    - \\# of epochs\n",
    "        - constant, or early stopping\n",
    "    - (`mini_batch_size` - this one might be canonical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Random Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the image size after a layer has been applied\n",
    "# assume all operations to be x/y symmetric\n",
    "def output_size(h_in, kernel_size, stride, padding):\n",
    "    \n",
    "    # Calculate output height and width\n",
    "    h_out = (h_in + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n",
    "    #w_out = (w_in + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1) // stride[1] + 1\n",
    "    \n",
    "    return h_out # = w_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def create_random_population(pop_size: int, \n",
    "                             max_2d_block_count: int = 3, \n",
    "                             max_kernel_size: int = 11,\n",
    "                             name_prefix=\"nn\",\n",
    "                             print_summary: bool = True) -> list[NN_individual]:\n",
    "    population = []\n",
    "    for i in range(pop_size):\n",
    "        genes_2d_block = []\n",
    "        input_image_size = IMAGE_HEIGHT # = IMAGE_WIDTH (assumed)\n",
    "        name=name_prefix+str(i)\n",
    "        if print_summary: print(f\"Individual '{name}' <-- ({input_image_size} x {input_image_size})\")\n",
    "        for j in range(random.randint(1, max_2d_block_count)):\n",
    "            if print_summary: print(f\"\\tBlock {j}\")\n",
    "            conv_kernel_size=min(random.randint(1,min(input_image_size, max_kernel_size)), random.randint(1,min(input_image_size, max_kernel_size)))\n",
    "            conv_stride=random.randint(1,conv_kernel_size)\n",
    "            conv_padding=random.randint(0,conv_kernel_size//2) # PyTorch: \"pad should be at most half of effective kernel size\"\n",
    "            # update input image size after convolutional layer\n",
    "            input_image_size = output_size(input_image_size, conv_kernel_size, conv_stride, conv_padding)\n",
    "            pool_kernel_size=min(random.randint(1,min(input_image_size, max_kernel_size)), random.randint(1,min(input_image_size, max_kernel_size)), random.randint(1,min(input_image_size, max_kernel_size)))\n",
    "            pool_stride=max(random.randint(1,pool_kernel_size), random.randint(1,pool_kernel_size))\n",
    "            pool_padding=random.randint(0,pool_kernel_size//2) # PyTorch: \"pad should be at most half of effective kernel size\"\n",
    "            block = Gene_2d_block(\n",
    "                # the following lower/upper bound values are not fine-tuned\n",
    "                out_channels=random.randint(3,15),\n",
    "                conv_kernel_size=conv_kernel_size,\n",
    "                conv_padding=conv_padding,\n",
    "                conv_stride=conv_stride,\n",
    "                pool_kernel_size=pool_kernel_size,\n",
    "                pool_padding=pool_padding,\n",
    "                pool_stride=pool_stride\n",
    "            )\n",
    "            genes_2d_block.append(block)\n",
    "            input_image_size = output_size(input_image_size, pool_kernel_size, pool_stride, pool_padding)\n",
    "            if print_summary: print(f\"{block.toString(tab_count=2)} --> ({input_image_size} x {input_image_size})\")\n",
    "        population.append(NN_individual(genes_2d_block=genes_2d_block, name=name))\n",
    "    return population\n",
    "testPop = create_random_population(pop_size=7, max_2d_block_count=3, print_summary=False)\n",
    "try:\n",
    "    for ind in testPop:\n",
    "        ind.eval()\n",
    "        with torch.inference_mode():\n",
    "            ind(testX)\n",
    "except:\n",
    "    print(\"oh, oh! exception\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness Evaluation\n",
    "We want a population that:\n",
    "- achieves high (validation/test data) accuracy after training\n",
    "    - the final accuracy `acc(NN1(t_final))` of an individual `NN1` is used\n",
    "- trains fast, i.e. takes little CPU time to achieve high accuracy called **Running Accuracy**\n",
    "    - the individual's accuracy `acc(NN1(t))` is summed over given timestamps `t`, like `Î£_t{acc(NN1(t))}`\n",
    "    - possibly we want to value early accuracy more, summing `Î£_t{acc(NN1(t))/t}` instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ind: NN_individual, X_in, y_true):\n",
    "    ind.eval()\n",
    "    with torch.inference_mode():\n",
    "        correct = torch.eq(ind(X_in), y_true).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(X_in)) * 100 \n",
    "    return acc # in percent\n",
    "\n",
    "# the momentary accuracy shall be the summand of the total running accuracy\n",
    "def momentary_accuracy(t: float, ind: NN_individual, X_in, y_true):\n",
    "    if t > 0:\n",
    "        running_acc = accuracy(ind, X_in, y_true)/t\n",
    "    else:\n",
    "        print(\"Got time t <= 0 in calculation of running_accuracy!\")\n",
    "        Exception\n",
    "    return running_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection\n",
    "To select, we need to train the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_one_epoch(ind: NN_individual, # <- model to be trained and then returned\n",
    "                          train_dl,  # <- train dataloader\n",
    "                          test_dl,   # <- test dataloader\n",
    "                          optimizer, # <- e.g. torch.optim.SGD(ind.parameters(), lr=.1)\n",
    "                          loss_fn=nn.CrossEntropyLoss(), \n",
    "                          device='cpu'):\n",
    "  train_loss = 0\n",
    "  for batch, (X, y) in enumerate(train_dl):\n",
    "    ind.train()\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    y_pred = ind(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    train_loss += loss\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  # Adjust train loss for number of batches\n",
    "  train_loss /= len(train_dl)\n",
    "\n",
    "  ### Testing loop\n",
    "  test_loss_total = 0\n",
    "  ind.eval()\n",
    "  with torch.inference_mode():\n",
    "    for batch, (X_test, y_test) in enumerate(test_dl):\n",
    "      X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "      test_pred = ind(X_test)\n",
    "      test_loss = loss_fn(test_pred, y_test)\n",
    "      test_loss_total += test_loss\n",
    "\n",
    "    test_loss_total /= len(test_dl)\n",
    "\n",
    "  # Print out what's happening\n",
    "  print(f\"Individual {ind.name}'s loss: {train_loss:.3f}, test loss: {test_loss_total:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the whole population simultaneously for one epoch each.\n",
    "The running accuracy is summed up on-the-fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def select(pop: list[NN_individual],\n",
    "           train_dl,  # <- train dataloader\n",
    "           test_dl,   # <- test dataloader\n",
    "           optimizer, # <- e.g. torch.optim.SGD(ind.parameters(), lr=.1)\n",
    "           max_epochs=5,\n",
    "           loss_fn=nn.CrossEntropyLoss(), \n",
    "           device='cpu') -> list[NN_individual]:\n",
    "  # each individual now obtains some fitness values that are now initialized:\n",
    "  pop_fitness = pd.DataFrame([{\"name\": ind.name, \"acc\": 0, \"running acc\": 0} for ind in pop])\n",
    "  # train each individual \"simultaneously\" by making the epoch-loop the outer one\n",
    "  for epoch in range(max_epochs):\n",
    "    print(f\"*** Commencing epoch {epoch} / {max_epochs}. ***\")\n",
    "    for i in range(len(pop)):\n",
    "      train_model_one_epoch(pop[i], \n",
    "                            train_dl=train_dl,\n",
    "                            test_dl=test_dl,\n",
    "                            optimizer=optimizer,\n",
    "                            loss_fn=loss_fn,\n",
    "                            device=device)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "immediate TODOs:\n",
    "- return `total_loss`, `total_acc` (total meaning over all batches) from `train_model_one_epoch`; probably in a dict\n",
    "- use those values to fill the `pop_fitness` `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
