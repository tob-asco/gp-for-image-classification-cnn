{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu121 running on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"{torch.__version__} running on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP Run for Image Classification\n",
    "Your problem needs to fulfill the following criteria.\n",
    "1. It is an image classification problem.\n",
    "2. You supply marked training images and marked validation images.\n",
    "\n",
    "Within those, the run is flexible and adapts itself to your problem.\n",
    "Now, please describe your images and problem by setting those global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 28 # <-- number of width-pixels\n",
    "IMAGE_HEIGHT = 28 # <-- number of height-pixels\n",
    "COLOUR_CHANNEL_COUNT = 1 # <-- RGB images would have 3\n",
    "CLASSIFICATION_CATEGORIES_COUNT = 10 # <-- the amount of possible categories of which each image shall be marked with one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Individuals' Class\n",
    "- The Hyperparamters should be passed to the constructor in a way that is both convenient for GP and for PyTorch.\n",
    "- I think I want to define a class for one `nn.Sequential` 2d-block\n",
    "    - All possible instances should be concatenable with all possible instances\n",
    "- Then, an individual is built from the concatenation of many such blocks, plus data preparation and final f.c. layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "define a Î» nn.Module that creates an nn layer from a given function\n",
    "this is handy for nn.Sequential usage '''\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "    \n",
    "'''\n",
    "create a function to reshape the (28x28) image input data '''\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testX.shape = torch.Size([1, 28, 28])\n",
      "testX[:,:3]: tensor([[[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431,\n",
      "          -1.6047, -0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594,\n",
      "          -0.7688,  0.7624,  1.6423, -0.1596, -0.4974,  0.4396, -0.7581,\n",
      "           1.0783,  0.8008,  1.6806,  1.2791,  1.2964,  0.6105,  1.3347],\n",
      "         [-0.2316,  0.0418, -0.2516,  0.8599, -1.3847, -0.8712, -0.2234,\n",
      "           1.7174,  0.3189, -0.4245,  0.3057, -0.7746, -1.5576,  0.9956,\n",
      "          -0.8798, -0.6011, -1.2742,  2.1228, -1.2347, -0.4879, -0.9138,\n",
      "          -0.6581,  0.0780,  0.5258, -0.4880,  1.1914, -0.8140, -0.7360],\n",
      "         [-1.4032,  0.0360, -0.0635,  0.6756, -0.0978,  1.8446, -1.1845,\n",
      "           1.3835,  1.4451,  0.8564,  2.2181,  0.5232,  0.3466, -0.1973,\n",
      "          -1.0546,  1.2780, -0.1722,  0.5238,  0.0566,  0.4263,  0.5750,\n",
      "          -0.6417, -2.2064, -0.7508,  0.0109, -0.3387, -1.3407, -0.5854]]])\n",
      "testBlock1(testX).shape = torch.Size([5, 14, 14])\n",
      "testBlock1(testX)[:1,:3]: tensor([[[0.7853, 1.0362, 0.9730, 1.3160, 0.0000, 0.6247, 0.9219, 1.3252,\n",
      "          0.6226, 0.5230, 0.7510, 0.6325, 0.1167, 0.4598],\n",
      "         [0.4979, 0.1404, 0.5680, 0.9011, 0.8487, 1.0509, 0.5997, 0.2775,\n",
      "          0.5622, 0.1151, 0.8709, 0.6784, 0.9692, 0.5829],\n",
      "         [0.9668, 0.2864, 0.6799, 0.4850, 0.0143, 0.1714, 0.3103, 1.1133,\n",
      "          0.3488, 1.3397, 0.3311, 0.7856, 0.1569, 1.2925]]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Sequential_block_2d(nn.Module):\n",
    "    def __init__(self, \n",
    "                 out_channels: int, # the number of output neurons after the full block\n",
    "                 in_channels: int = 1, # should not be set here, but is set in Individual's __init__()\n",
    "                 conv_kernel_size: int = 3,\n",
    "                 conv_stride: int = 1,\n",
    "                 conv_padding: int = 1,\n",
    "                 pool_kernel_size: int = 2,\n",
    "                 pool_stride: int = 2,\n",
    "                 pool_padding: int = 0):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels,\n",
    "                      out_channels=out_channels,\n",
    "                      kernel_size=conv_kernel_size,\n",
    "                      stride=conv_stride,\n",
    "                      padding=conv_padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_kernel_size,\n",
    "                         stride=pool_stride,\n",
    "                         padding=pool_padding)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "# generate some testing blocks (TODO: write actual unit tests)\n",
    "testBlock1 = Sequential_block_2d(in_channels=1,out_channels=5)\n",
    "testBlock2 = Sequential_block_2d(in_channels=5,out_channels=3)\n",
    "torch.manual_seed(42)\n",
    "testX = torch.randn(COLOUR_CHANNEL_COUNT,IMAGE_WIDTH,IMAGE_HEIGHT)\n",
    "testBlock1, testBlock2, testX, testBlock1(testX)\n",
    "print(f\"testX.shape = {testX.shape}\\ntestX[:,:3]: {testX[:,:3]}\")\n",
    "print(f\"testBlock1(testX).shape = {testBlock1(testX).shape}\\ntestBlock1(testX)[:1,:3]: {testBlock1(testX)[:1,:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0558,  0.1462,  0.3317, -0.0600, -0.0368, -0.1696, -0.0155,  0.1255,\n",
       "         0.0796,  0.0911], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class for image classification individuals\n",
    "class NN_individual(nn.Module):\n",
    "    def __init__(self, blocks_2d: list[Sequential_block_2d],\n",
    "                 in_dimensions: int = COLOUR_CHANNEL_COUNT,\n",
    "                 out_dimensions: int = CLASSIFICATION_CATEGORIES_COUNT,\n",
    "                 fin_res: int = 5): # output dimension of the final max pooling \n",
    "                                    # producing size (fin_res * fin_res)\n",
    "        super().__init__()\n",
    "        self.blocks_2d = blocks_2d\n",
    "        # add a final max pool\n",
    "        # Why? Because then torch handles the dimensions through the \"adaptive\"ness\n",
    "        self.last_max_pool_adaptive = nn.AdaptiveAvgPool2d((fin_res, fin_res))\n",
    "        self.flatten = nn.Flatten(start_dim=0, end_dim=-1) # default start_dim = 1\n",
    "        self.lin = nn.Linear(in_features = fin_res * fin_res * blocks_2d[-1].out_channels,\n",
    "                      out_features = out_dimensions)\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.blocks_2d)):\n",
    "            x = self.blocks_2d[i](x)\n",
    "        x = self.last_max_pool_adaptive(x)\n",
    "        #print(f\"last_max_pool_adaptive output shape is {x.shape}\")\n",
    "        x = self.flatten(x)\n",
    "        #print(f\"flatten output shape is {x.shape}\")\n",
    "        x = self.lin(x)\n",
    "        #print(f\"lin output shape is {x.shape}\")\n",
    "        return x\n",
    "    \n",
    "testIndividual = NN_individual(blocks_2d=[testBlock1, testBlock2])\n",
    "testIndividual(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_channels of the first needs to match in_channels of the second!\n",
      "in_channels of the first gene needs to match the COLOUR_CHANNEL_COUNT of the problem!\n"
     ]
    }
   ],
   "source": [
    "# this way, adjacent genes (= 2d_blocks) need to have the correct dimensions\n",
    "# e.g. the following will error:\n",
    "badIndividual = NN_individual([Sequential_block_2d(in_channels=1,out_channels=2), Sequential_block_2d(in_channels=3, out_channels=5)])\n",
    "try:\n",
    "    print(badIndividual(testX))\n",
    "except:\n",
    "    print(\"out_channels of the first needs to match in_channels of the second!\")\n",
    "\n",
    "# but there's more redundancy:\\the first gene needs to have the same number of in_channels as there are colour channels\n",
    "# e.g. the following will error:\n",
    "badIndividual = NN_individual([Sequential_block_2d(in_channels=COLOUR_CHANNEL_COUNT + 1,out_channels=5)])\n",
    "try:\n",
    "    print(badIndividual(testX))\n",
    "except:\n",
    "    print(\"in_channels of the first gene needs to match the COLOUR_CHANNEL_COUNT of the problem!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brainstorm on How to Encode Individuals\n",
    "We need to talk about this right now because we want to adapt our `NN_individual.blocks_2d` definition according to it.\n",
    "The options are:\n",
    "1. We specify `Sequential_block_2d.in_channels` and `~.out_channels` separately for each individual and only allow concatenation if the criteria are met. This is probably not super clever...\n",
    "2. Genotype-closure: The parameters that are adapted through GP will never leave the space of syntacticly correct indivuals\n",
    "    - The first gene is not allowed to choose `~.in_channels`, it must match `COLOUR_CHANNEL_COUNT`\n",
    "    - Every gene but the first is not allowed to choose `~.in_channels`, it must match `~.out_channels` of the prior gene\n",
    "    - How will this change the gene class `Sequential_block_2d`?\n",
    "        - Set `Sequential_block_2d.in_channels` only programatically, in `NN_individual.__init__()`\n",
    "        - Don't even let the genes inherit from `nn.Module`, only the individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for the genetic information of one 2d block\n",
    "class Gene_2d_block:\n",
    "    def __init__(self,\n",
    "                 out_channels: int,\n",
    "                 in_channels: int = None, # set in the individual's constructor\n",
    "                 conv_kernel_size: int = 3,\n",
    "                 conv_stride: int = 1,\n",
    "                 conv_padding: int = 1,\n",
    "                 pool_kernel_size: int = 2,\n",
    "                 pool_stride: int = 2,\n",
    "                 pool_padding: int = 0):\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_kernel_size = conv_kernel_size\n",
    "        self.conv_stride = conv_stride\n",
    "        self.conv_padding = conv_padding\n",
    "        self.pool_kernel_size = pool_kernel_size\n",
    "        self.pool_stride = pool_stride\n",
    "        self.pool_padding = pool_padding\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3372, -0.1906, -0.0482,  0.1216,  0.2394,  0.2883,  0.1874, -0.4645,\n",
       "         0.1251,  0.0770], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class for image classification individuals\n",
    "class NN_individual(nn.Module):\n",
    "    def __init__(self, genes_2d_block: list[Gene_2d_block]): \n",
    "        super().__init__()\n",
    "        ''' build the full sequential from the gene information (genes_2d_block) '''\n",
    "        self.blocks_2d = []\n",
    "        # the first 2d_block needs to have as many in_channels as there are colour channels\n",
    "        # the others need to have as in_channels the number of out_channels from the previous block\n",
    "        for i in range(len(genes_2d_block)):\n",
    "            if i == 0:\n",
    "                in_channels = COLOUR_CHANNEL_COUNT\n",
    "            else:\n",
    "                in_channels = genes_2d_block[i-1].out_channels\n",
    "            self.blocks_2d.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels,\n",
    "                    out_channels=genes_2d_block[i].out_channels,\n",
    "                    kernel_size=genes_2d_block[i].conv_kernel_size,\n",
    "                    stride=genes_2d_block[i].conv_stride,\n",
    "                    padding=genes_2d_block[i].conv_padding),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=genes_2d_block[i].pool_kernel_size,\n",
    "                    stride=genes_2d_block[i].pool_stride,\n",
    "                    padding=genes_2d_block[i].pool_padding)))\n",
    "        self.flatten = nn.Flatten(start_dim=0, end_dim=-1) # default start_dim = 1\n",
    "        self.lazyLin = nn.LazyLinear(out_features = CLASSIFICATION_CATEGORIES_COUNT) # automatically infers the number of channels\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.blocks_2d)):\n",
    "            x = self.blocks_2d[i](x)\n",
    "        x = self.flatten(x)\n",
    "        #print(f\"flatten output shape is {x.shape}\")\n",
    "        x = self.lazyLin(x)\n",
    "        #print(f\"lin output shape is {x.shape}\")\n",
    "        return x\n",
    "    \n",
    "testIndividual = NN_individual(genes_2d_block=[Gene_2d_block(out_channels=4), Gene_2d_block(out_channels=7)])\n",
    "testIndividual(testX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
